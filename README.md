# Data-Mining-Project
dataset accuracy measurement and classifier accuracy
This project mainly works with a different classifier. The accuracy measures how it correctly classifies the data set.

There are a total of 13549 instances of these 7 attributes in our dataset.
The targeted features are: Housing In London, Monthly Variable 
The dataset was collected from Kaggle.com.

For the first portion, we used the supervised learning dataset. Data mining using labelled data is known as supervised learning. Where labelled data is a specially designated attribute and the 
The aim is to use the data given to predict the value of that attribute for 
In the instance that has not been seen before, we used the Naive Bayes Classifier and we got 99.91% correctly classified.
After applying the Naive Bayes classifier we applied the  KNN classifier we got an accuracy is 99.97% which means correctly classifying the dataset is 99.97%.
In task-2 part  We make the test data set from the supervised learning data set that we have been using before.

We take here 2709 instances & 7 attributes in this data set.

After using the j48 classifier, we got an accuracy of 99.92%, which means the accuracy rate is lower than the supervised learning dataset, which is 99.97%(after using the KNN classifier).
In task 3 we are working with the unsupervised learning dataset. Unsupervised Learninlearningachine learning technique in which the users do not need to supervise the model. Instead, it allows the model to work on its own to discover patterns and information that were previously undetected. It mainly deals with unlabeled data.
The targeted features are: accidental-deaths-in-USA-monthly
We use the K Means Clustering Algorithm.
used “accidental-deaths-in-USA-monthly”, a CSV dataset file [later converted into.arff] collected from Kaggle.com. 
K-Means Clustering is an unsupervised learning algorithm, which 
This groups the unlabeled dataset into different clusters. Here, K defines the 
The number of pre-defined clusters that need to be created in the process, 
If K = 2, there will be two clusters, and for K = 3, there will be three. 
clusters, and so on. 
Result: Clustered Instances
0  28(39%)
1 44 (61%).
